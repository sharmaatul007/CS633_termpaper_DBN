{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install GPUtil\nimport scipy.io\nimport torch\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation\nimport torch.nn as nn\nimport numpy as np\nfrom tqdm import tqdm\nimport random\nfrom PIL import Image\nimport glob\nimport math\nimport os\nfrom IPython.display import HTML\nimport struct\nimport kornia\nfrom skimage import feature\nfrom GPUtil import showUtilization as gpu_usage\nfrom torch.nn.utils.weight_norm import weight_norm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-09T04:47:29.267416Z","iopub.execute_input":"2022-06-09T04:47:29.267747Z","iopub.status.idle":"2022-06-09T04:47:41.274541Z","shell.execute_reply.started":"2022-06-09T04:47:29.267715Z","shell.execute_reply":"2022-06-09T04:47:41.273766Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"DATA_FOLDER = \"/kaggle/input/the-small-norb-dataset-v10/\"\n\nPREFIXES = {\n    'train': 'smallnorb-5x46789x9x18x6x2x96x96-training-',\n    'test': 'smallnorb-5x01235x9x18x6x2x96x96-testing-',\n}\n\nFILE_TYPES = ['info', 'cat', 'dat']\n\n# helper function to read int from file\ndef read_int(f):\n    num, = struct.unpack('i', f.read(4))\n    return num\n\n\n# From https://cs.nyu.edu/~ylclab/data/norb-v1.0-small/ \n# \"The magic number encodes the element type of the matrix\"\n# Note: I only copied over the ones I needed for these files.\nmap_magic_number_to_data_type = {\n    '1e3d4c55': np.uint8,\n    '1e3d4c54': np.int32,\n}\n\nloaded_data = {}\n\nfor dataset, prefix in PREFIXES.items():\n    for filetype in FILE_TYPES:\n        filename = prefix + filetype + \".mat\"\n        print('Reading {}'.format(filename))\n        \n        file_loc = os.path.join(DATA_FOLDER, filename)\n        with open( file_loc, 'rb') as f:\n            # Read the magic_num, convert it to hexadecimal, and look up the data_type\n            raw_magic_num = read_int(f)\n            magic_num = format(raw_magic_num, '02x')\n            data_type = map_magic_number_to_data_type[magic_num]\n            print('dtype', data_type)\n\n            # Read how many dimensions to expect\n            ndim = read_int(f)\n            \n            # Read at least 3 ints, or however many ndim there are\n            shape = [\n                read_int(f)\n                for i in range(max(ndim, 3))\n            ]   \n            # But in case ndims < 3, take at most n_dim elements\n            shape = shape[:ndim]\n            print('shape', shape)\n    \n            # Now load the actual data!\n            loaded_data[(dataset, filetype)] = np.fromfile(\n                f, \n                dtype=data_type, \n                count=np.prod(shape)\n            ).reshape(shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-09T04:47:41.276519Z","iopub.execute_input":"2022-06-09T04:47:41.276888Z","iopub.status.idle":"2022-06-09T04:47:48.459804Z","shell.execute_reply.started":"2022-06-09T04:47:41.276852Z","shell.execute_reply":"2022-06-09T04:47:48.458828Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"x_raw = torch.Tensor(loaded_data[('train', 'dat')]) / 255.\ny = torch.Tensor(loaded_data[('train', 'cat')])\ninfo = torch.Tensor(loaded_data[('train', 'info')])\nx = torch.zeros(5,5,972,2,96,96)\ncount = 0\ninstances = [4,6,7,8,9]\n\nfor lab in range(5):\n    \n    for ins in range(5):\n        \n        count=0\n        \n        for lig in range(6):\n        \n            for ele in range(9):\n            \n                for azi in range(18):\n                    \n                    x[lab,ins,count] = \\\n                        x_raw[(y==lab)&\\\n                        (info[:,0]==instances[ins])&\\\n                        (info[:,1]==ele)&\\\n                        (info[:,2]==azi*2)&\\\n                        (info[:,3]==lig)]\n                    count += 1","metadata":{"execution":{"iopub.status.busy":"2022-06-09T04:47:48.461631Z","iopub.execute_input":"2022-06-09T04:47:48.462148Z","iopub.status.idle":"2022-06-09T04:48:01.352607Z","shell.execute_reply.started":"2022-06-09T04:47:48.462108Z","shell.execute_reply":"2022-06-09T04:48:01.351824Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"x = x.view(-1, 1, 96, 96)\nx = x[:,:,10:-10,10:-10][torch.randperm(x.shape[0])].cuda()","metadata":{"execution":{"iopub.status.busy":"2022-06-09T04:48:01.354043Z","iopub.execute_input":"2022-06-09T04:48:01.354370Z","iopub.status.idle":"2022-06-09T04:48:06.629389Z","shell.execute_reply.started":"2022-06-09T04:48:01.354335Z","shell.execute_reply":"2022-06-09T04:48:06.628625Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"N_TEMP = 80\nT_SIZE = 13\nF_COMP = 5\nTAU = 0.1","metadata":{"execution":{"iopub.status.busy":"2022-06-09T04:48:06.632194Z","iopub.execute_input":"2022-06-09T04:48:06.632541Z","iopub.status.idle":"2022-06-09T04:48:06.637478Z","shell.execute_reply.started":"2022-06-09T04:48:06.632503Z","shell.execute_reply":"2022-06-09T04:48:06.636667Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class StructSpars(nn.Module):\n    \n    def __init__(self):\n        \n        super().__init__()\n        \n        self.expander = weight_norm(nn.Conv2d(1, N_TEMP, T_SIZE, bias=False))\n        \n        self.encoder = nn.Conv2d(N_TEMP, N_TEMP, F_COMP, padding=F_COMP//2, bias=False)\n                \n        self.inhibitor = nn.Conv2d(N_TEMP, N_TEMP, F_COMP, padding=F_COMP//2, bias=True)\n\n        self.decoder = weight_norm(nn.ConvTranspose2d(N_TEMP, N_TEMP, T_SIZE, groups=N_TEMP, bias=False))\n                \n        self.blender =  nn.Conv2d(N_TEMP, N_TEMP, F_COMP, padding=F_COMP//2, bias=True)\n        \n        \n    def forward(self, x):\n        \n        expanded = torch.relu(self.expander(x))\n        \n        code = torch.relu(self.encoder(expanded))\n                \n        inh_factors = self.inhibitor(expanded)\n        \n        inh_tiles = F.unfold(inh_factors, F_COMP*2, stride=F_COMP) \n                        \n        inh_tiles = F.gumbel_softmax(inh_tiles, TAU, dim=1)\n                \n        inh_mask = F.fold(inh_tiles, inh_factors.shape[-2:], F_COMP*2, stride=F_COMP)\n                \n        del inh_tiles, inh_factors, expanded\n        \n        overflow = inh_mask > 1.\n        \n        normaliser = torch.ones(inh_mask.shape, device=x.device) * (~ overflow) + overflow * inh_mask.detach()\n        \n        inh_mask = inh_mask / normaliser\n            \n        sparse_code = code * inh_mask\n        \n        del code, normaliser, overflow\n        \n        raw_reco = torch.relu(self.decoder(sparse_code))\n                                \n        ble_factors = self.blender(raw_reco)\n        \n        ble_mask = F.gumbel_softmax(ble_factors, TAU, dim=1)\n                \n        sparse_reco = raw_reco * ble_mask\n        \n        reco = torch.sum(sparse_reco, dim=1, keepdim=True)\n                \n        return reco, sparse_code, sparse_reco\n    \n    \n    def get_templates(self):\n        \n        return self.decoder.weight.data\n    \n    def get_encoders(self):\n        \n        return self.expander.weight.data","metadata":{"execution":{"iopub.status.busy":"2022-06-09T04:48:06.639768Z","iopub.execute_input":"2022-06-09T04:48:06.640348Z","iopub.status.idle":"2022-06-09T04:48:06.654510Z","shell.execute_reply.started":"2022-06-09T04:48:06.640311Z","shell.execute_reply":"2022-06-09T04:48:06.653327Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def log_losses(reco, img, sparse_code, sparse_reco):\n    \n    diff = (reco - img) **2\n    \n    mse_loss = torch.mean(diff)\n    \n    activations = sparse_code.mean(dim=(0,2,3))\n\n    code_spars_loss = (activations / activations.mean()).std()\n                        \n    activations = sparse_reco.mean(dim=(0,2,3))\n        \n    reco_spars_loss = (activations / activations.mean()).std()\n    \n    return 10*mse_loss, 0.1*code_spars_loss, 0.1*reco_spars_loss","metadata":{"execution":{"iopub.status.busy":"2022-06-09T04:48:06.655938Z","iopub.execute_input":"2022-06-09T04:48:06.656478Z","iopub.status.idle":"2022-06-09T04:48:06.665656Z","shell.execute_reply.started":"2022-06-09T04:48:06.656445Z","shell.execute_reply":"2022-06-09T04:48:06.664813Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def get_log(size, std):\n    \n    distance = torch.arange(size) - size//2\n    \n    x = distance.expand(1,1,size,size)**2\n    \n    y = x.transpose(-1,-2)\n    \n    t = (x + y) / (2*std**2)\n    \n    LoG = -1/(math.pi*std**4) * (1-t) * torch.exp(-t)\n    \n    return LoG","metadata":{"execution":{"iopub.status.busy":"2022-06-09T04:48:06.667054Z","iopub.execute_input":"2022-06-09T04:48:06.667627Z","iopub.status.idle":"2022-06-09T04:48:06.676102Z","shell.execute_reply.started":"2022-06-09T04:48:06.667576Z","shell.execute_reply":"2022-06-09T04:48:06.675239Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"SHARPNESS = 75\n\nplt.figure(figsize=(20,10))\nplt.subplot(1,2,1)\nplt.imshow(x[1,0].detach().cpu(), cmap=\"gray\")\n\nlog = get_log(5, 0.7).cuda()\nx = F.conv2d(x, log)\nx = torch.relu(x)\nx = torch.sigmoid(x*SHARPNESS)\n\nx = x - torch.min(x.reshape(x.shape[0], -1), dim=1)[0].view(-1,1,1,1)\nx = x / torch.max(x.reshape(x.shape[0], -1), dim=1)[0].view(-1,1,1,1)\n\nplt.subplot(1,2,2)\nplt.imshow(x[1,0].detach().cpu(), cmap=\"gray\")\n\nplt.show()\nx.min(), x.max(), x.mean()","metadata":{"execution":{"iopub.status.busy":"2022-06-09T04:48:06.677336Z","iopub.execute_input":"2022-06-09T04:48:06.677816Z","iopub.status.idle":"2022-06-09T04:48:07.791377Z","shell.execute_reply.started":"2022-06-09T04:48:06.677779Z","shell.execute_reply":"2022-06-09T04:48:07.790666Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"split = (x.shape[0]//100)*80\nxtrain = x[:split]\nxval = x[split:]\nxtrain.shape, xval.shape\ndel x","metadata":{"execution":{"iopub.status.busy":"2022-06-09T04:48:07.792580Z","iopub.execute_input":"2022-06-09T04:48:07.792915Z","iopub.status.idle":"2022-06-09T04:48:07.797582Z","shell.execute_reply.started":"2022-06-09T04:48:07.792881Z","shell.execute_reply":"2022-06-09T04:48:07.796727Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def free_gpu_cache():\n    print(\"Initial GPU Usage\")\n    gpu_usage()                             \n    torch.cuda.empty_cache()\n    print(\"GPU Usage after emptying the cache\")\n    gpu_usage()\n\nfree_gpu_cache()                           ","metadata":{"execution":{"iopub.status.busy":"2022-06-09T04:48:07.799038Z","iopub.execute_input":"2022-06-09T04:48:07.799467Z","iopub.status.idle":"2022-06-09T04:48:07.960815Z","shell.execute_reply.started":"2022-06-09T04:48:07.799432Z","shell.execute_reply":"2022-06-09T04:48:07.959996Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def propagation(model, sample, b):\n    \n    reco, inh_mask, ble_mask = model(sample[b*B_SIZE:(b+1)*B_SIZE])\n    \n    mse, cod, tem = log_losses(reco, sample[b*B_SIZE:(b+1)*B_SIZE], inh_mask, ble_mask)\n    \n    loss = mse + cod + tem\n    \n    optimiser.zero_grad()\n    loss.backward()\n    optimiser.step()","metadata":{"execution":{"iopub.status.busy":"2022-06-09T04:48:07.962463Z","iopub.execute_input":"2022-06-09T04:48:07.962839Z","iopub.status.idle":"2022-06-09T04:48:07.969791Z","shell.execute_reply.started":"2022-06-09T04:48:07.962800Z","shell.execute_reply":"2022-06-09T04:48:07.968838Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def evaluation(model, sampleval, b):\n    \n    reco, inh_mask, ble_mask = model(sampleval[b*B_SIZE:(b+1)*B_SIZE])\n    \n    mse, cod, tem = log_losses(reco, sampleval[b*B_SIZE:(b+1)*B_SIZE], inh_mask, ble_mask)\n    \n    return mse, cod, tem","metadata":{"execution":{"iopub.status.busy":"2022-06-09T04:48:07.971053Z","iopub.execute_input":"2022-06-09T04:48:07.971861Z","iopub.status.idle":"2022-06-09T04:48:07.977943Z","shell.execute_reply.started":"2022-06-09T04:48:07.971787Z","shell.execute_reply":"2022-06-09T04:48:07.976973Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"model = StructSpars().cuda()\noptimiser = torch.optim.Adam(model.parameters())","metadata":{"execution":{"iopub.status.busy":"2022-06-09T04:48:07.979168Z","iopub.execute_input":"2022-06-09T04:48:07.979497Z","iopub.status.idle":"2022-06-09T04:48:08.004212Z","shell.execute_reply.started":"2022-06-09T04:48:07.979465Z","shell.execute_reply":"2022-06-09T04:48:08.003617Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 10\nB_SIZE = 128\nnval = xval.shape[0] // B_SIZE\nn_b = xtrain.shape[0] // B_SIZE\nlosstracker = torch.zeros((nval, 3)).cuda()\ntemptracker = torch.zeros((EPOCHS, N_TEMP*2, 1, T_SIZE, T_SIZE))\n\nfor e in range(EPOCHS): \n\n    temptracker[e,:N_TEMP] = model.get_templates().detach().cpu()\n    temptracker[e,N_TEMP:] = model.get_encoders().detach().cpu()\n    \n    xtrain = xtrain[torch.randperm(xtrain.shape[0])]\n    progress_bar = tqdm(range(n_b), position=0, leave=True)\n    \n    with torch.no_grad():\n        \n        for b in range(nval):\n            \n            losstracker[b,0],losstracker[b,1],losstracker[b,2] = \\\n                                                        evaluation(model, xval, b)\n            \n    progress_bar.set_description(\\\n                                    \"E:\"+ str(e) +\\\n                                    \" MSE:\" + format(losstracker[:,0].mean(),\".3f\") +\\\n                                    \" COD:\" + format(losstracker[:,1].mean(),\".3f\") +\\\n                                    \" TEM:\" + format(losstracker[:,2].mean(),\".3f\") +\\\n                                    \" TOT:\" + format(losstracker.sum(1).mean(),\".3f\"))\n            \n    for b in progress_bar:\n        \n        propagation(model, xtrain, b) ","metadata":{"execution":{"iopub.status.busy":"2022-06-09T04:48:08.006803Z","iopub.execute_input":"2022-06-09T04:48:08.007052Z","iopub.status.idle":"2022-06-09T05:17:44.134869Z","shell.execute_reply.started":"2022-06-09T04:48:08.007029Z","shell.execute_reply":"2022-06-09T05:17:44.133991Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"torch.save(temptracker, 'temps.pt')\ntorch.save(model.state_dict(), 'weights.pth')","metadata":{"execution":{"iopub.status.busy":"2022-06-09T05:17:44.136307Z","iopub.execute_input":"2022-06-09T05:17:44.136869Z","iopub.status.idle":"2022-06-09T05:17:44.558907Z","shell.execute_reply.started":"2022-06-09T05:17:44.136829Z","shell.execute_reply":"2022-06-09T05:17:44.558145Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"S = 56\ntestreco, code, blend = model(xval[S:S+2])\ntestreco = testreco.detach().cpu()\ncode = code.detach().cpu()\nblend = blend.detach().cpu()\n\nplt.figure(figsize=(30,10))\nplt.subplot(1,4,1)\nplt.imshow(testreco[0,0], cmap=\"gray\")\nplt.subplot(1,4,2)\nplt.imshow(testreco[1,0], cmap=\"gray\")\nplt.subplot(1,4,3)\nplt.imshow(xval[S,0].detach().cpu(), cmap=\"gray\")\nplt.subplot(1,4,4)\nplt.imshow(xval[S+1,0].detach().cpu(), cmap=\"gray\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-08T05:25:03.554676Z","iopub.execute_input":"2022-06-08T05:25:03.555011Z","iopub.status.idle":"2022-06-08T05:25:04.072713Z","shell.execute_reply.started":"2022-06-08T05:25:03.554982Z","shell.execute_reply":"2022-06-08T05:25:04.071842Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"templates = model.get_templates().detach().cpu()\nencoders = model.get_encoders().detach().cpu()\nROWS = 8\n\nplt.figure(figsize=(30,30))\n\nfor i in range(N_TEMP):\n    \n    img = templates[i].permute(1,2,0)\n    plt.subplot(ROWS*2, N_TEMP//ROWS, i+1)\n    plt.imshow(img, cmap=\"gray\")\n    \nfor i in range(N_TEMP):\n    \n    img = encoders[i].permute(1,2,0)\n    plt.subplot(ROWS*2, N_TEMP//ROWS, N_TEMP+i+1)\n    plt.imshow(img, cmap=\"gray\")\n    \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-08T05:25:06.738827Z","iopub.execute_input":"2022-06-08T05:25:06.739155Z","iopub.status.idle":"2022-06-08T05:25:18.301633Z","shell.execute_reply.started":"2022-06-08T05:25:06.739123Z","shell.execute_reply":"2022-06-08T05:25:18.300680Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"print((code.mean((0,-1,-2))*10000).round().int())\nprint((blend.mean((0,-1,-2))*10000).round().int())","metadata":{"execution":{"iopub.status.busy":"2022-06-08T05:25:18.303345Z","iopub.execute_input":"2022-06-08T05:25:18.303666Z","iopub.status.idle":"2022-06-08T05:25:18.317271Z","shell.execute_reply.started":"2022-06-08T05:25:18.303635Z","shell.execute_reply":"2022-06-08T05:25:18.316623Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(30,10))\nS1 = 3\n\nfor i in range(N_TEMP):\n    \n    img = code[0,i].detach().cpu()\n    plt.subplot(8, N_TEMP/4, i+1)\n    plt.imshow(img, cmap=\"gray\")\n    \nfor i in range(N_TEMP):\n    \n    img = blend[0,i].detach().cpu()\n    plt.subplot(8, N_TEMP/4, N_TEMP+i+1)\n    plt.imshow(img, cmap=\"gray\")\n    \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-08T05:25:18.320088Z","iopub.execute_input":"2022-06-08T05:25:18.320332Z","iopub.status.idle":"2022-06-08T05:25:28.955180Z","shell.execute_reply.started":"2022-06-08T05:25:18.320308Z","shell.execute_reply":"2022-06-08T05:25:28.954170Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(30,10))\nplt.subplot(1,4,1)\nplt.imshow(code[1].mean((0)).detach().cpu())\nplt.subplot(1,4,2)\nplt.imshow(code[1].mean((0)).detach().cpu())\nplt.subplot(1,4,3)\nplt.imshow(blend[1].mean((0)).detach().cpu())\nplt.subplot(1,4,4)\nplt.imshow(blend[1,6].detach().cpu())","metadata":{"execution":{"iopub.status.busy":"2022-06-08T05:25:28.956656Z","iopub.execute_input":"2022-06-08T05:25:28.957247Z","iopub.status.idle":"2022-06-08T05:25:29.738113Z","shell.execute_reply.started":"2022-06-08T05:25:28.957200Z","shell.execute_reply":"2022-06-08T05:25:29.737269Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"sum(p.numel() for p in model.parameters() if p.requires_grad)","metadata":{"execution":{"iopub.status.busy":"2022-06-08T05:25:29.740069Z","iopub.execute_input":"2022-06-08T05:25:29.740326Z","iopub.status.idle":"2022-06-08T05:25:29.746642Z","shell.execute_reply.started":"2022-06-08T05:25:29.740300Z","shell.execute_reply":"2022-06-08T05:25:29.745774Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# weight norm improved stability in training but too small problem","metadata":{"execution":{"iopub.status.busy":"2022-06-08T04:47:07.932621Z","iopub.status.idle":"2022-06-08T04:47:07.933427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}